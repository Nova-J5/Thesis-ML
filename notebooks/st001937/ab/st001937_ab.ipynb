{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ST001937 - AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost e classificazione multiclasse\n",
    "L'algoritmo **AdaBoost** è stato originariamente progettato per problemi di classificazione binaria, ma può essere esteso per gestire problemi di classificazione multiclasse mediante due tecniche di estensione, **One-vs-All** e **One-vs-One**:\n",
    "- **One-vs-All (OvA)**: viene addestrato un classificatore binario per ogni classe, considerando una classe come positiva e tutte le altre come negative. Per classificare un'istanza, vengono eseguiti tutti i classificatori e l'istanza è assegnata alla classe del classificatore che restituisce la classificazione migliore.\n",
    "- **One-vs-One (OvO)**: viene addestrato un classificatore binario per ciascuna coppia di classi possibili. Quando si classifica un'istanza, ogni classificatore restituisce un voto per la sua classe associata. L'istanza è assegnata alla classe con il maggior numero di voti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# Librerie di base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librerie per la Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Librerie per il Machine Learning\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "\n",
    "# Librerie per la Features Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# Librerie per la PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('All packages successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data & Peak Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pheotypes</th>\n",
       "      <th>1,3,5(10)-estratrien-3,6- beta-17-beta-triol</th>\n",
       "      <th>1,5-anhydroglucitol</th>\n",
       "      <th>17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-1</th>\n",
       "      <th>17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-2</th>\n",
       "      <th>17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-3</th>\n",
       "      <th>17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-4</th>\n",
       "      <th>17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-5</th>\n",
       "      <th>17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-6</th>\n",
       "      <th>1-hexadecanol</th>\n",
       "      <th>...</th>\n",
       "      <th>tyrosine-1</th>\n",
       "      <th>tyrosine-2</th>\n",
       "      <th>urea-1</th>\n",
       "      <th>urea-2</th>\n",
       "      <th>urea-3</th>\n",
       "      <th>urea-4</th>\n",
       "      <th>uridine</th>\n",
       "      <th>valine</th>\n",
       "      <th>xanthine</th>\n",
       "      <th>xanthosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benign SPNS</td>\n",
       "      <td>0.437408</td>\n",
       "      <td>0.663764</td>\n",
       "      <td>0.700609</td>\n",
       "      <td>0.096924</td>\n",
       "      <td>0.173891</td>\n",
       "      <td>0.799124</td>\n",
       "      <td>0.573520</td>\n",
       "      <td>1.105910</td>\n",
       "      <td>0.677833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689488</td>\n",
       "      <td>0.037373</td>\n",
       "      <td>0.595031</td>\n",
       "      <td>0.234936</td>\n",
       "      <td>0.589201</td>\n",
       "      <td>0.127788</td>\n",
       "      <td>0.113960</td>\n",
       "      <td>0.216687</td>\n",
       "      <td>0.770860</td>\n",
       "      <td>0.174060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benign SPNS</td>\n",
       "      <td>5.064922</td>\n",
       "      <td>0.653161</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>0.056551</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.394648</td>\n",
       "      <td>0.772451</td>\n",
       "      <td>0.623514</td>\n",
       "      <td>0.769287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537845</td>\n",
       "      <td>0.016517</td>\n",
       "      <td>0.484474</td>\n",
       "      <td>0.564398</td>\n",
       "      <td>0.482784</td>\n",
       "      <td>0.119055</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>0.164879</td>\n",
       "      <td>0.456740</td>\n",
       "      <td>0.320723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benign SPNS</td>\n",
       "      <td>1.046057</td>\n",
       "      <td>0.798040</td>\n",
       "      <td>0.838630</td>\n",
       "      <td>0.283674</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>0.032103</td>\n",
       "      <td>0.807268</td>\n",
       "      <td>0.339667</td>\n",
       "      <td>1.104029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679699</td>\n",
       "      <td>1.079720</td>\n",
       "      <td>0.901623</td>\n",
       "      <td>0.559234</td>\n",
       "      <td>0.866856</td>\n",
       "      <td>0.159342</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>0.252849</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.158255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benign SPNS</td>\n",
       "      <td>2.530700</td>\n",
       "      <td>1.318840</td>\n",
       "      <td>1.074717</td>\n",
       "      <td>0.431186</td>\n",
       "      <td>1.773602</td>\n",
       "      <td>0.627714</td>\n",
       "      <td>2.042268</td>\n",
       "      <td>0.913226</td>\n",
       "      <td>0.741269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837193</td>\n",
       "      <td>0.522064</td>\n",
       "      <td>1.433745</td>\n",
       "      <td>1.442062</td>\n",
       "      <td>1.406062</td>\n",
       "      <td>0.231101</td>\n",
       "      <td>0.278952</td>\n",
       "      <td>0.301997</td>\n",
       "      <td>0.940990</td>\n",
       "      <td>1.095022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benign SPNS</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>1.031146</td>\n",
       "      <td>0.863596</td>\n",
       "      <td>0.201422</td>\n",
       "      <td>0.222126</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>1.004769</td>\n",
       "      <td>0.403102</td>\n",
       "      <td>0.790744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826921</td>\n",
       "      <td>0.462153</td>\n",
       "      <td>1.040359</td>\n",
       "      <td>1.154850</td>\n",
       "      <td>1.034635</td>\n",
       "      <td>0.198105</td>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.302138</td>\n",
       "      <td>1.208439</td>\n",
       "      <td>0.557425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 546 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pheotypes  1,3,5(10)-estratrien-3,6- beta-17-beta-triol  \\\n",
       "0  Benign SPNS                                      0.437408   \n",
       "1  Benign SPNS                                      5.064922   \n",
       "2  Benign SPNS                                      1.046057   \n",
       "3  Benign SPNS                                      2.530700   \n",
       "4  Benign SPNS                                      0.027033   \n",
       "\n",
       "   1,5-anhydroglucitol  17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-1  \\\n",
       "0             0.663764                                       0.700609   \n",
       "1             0.653161                                       0.883121   \n",
       "2             0.798040                                       0.838630   \n",
       "3             1.318840                                       1.074717   \n",
       "4             1.031146                                       0.863596   \n",
       "\n",
       "   17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-2  \\\n",
       "0                                       0.096924   \n",
       "1                                       0.056551   \n",
       "2                                       0.283674   \n",
       "3                                       0.431186   \n",
       "4                                       0.201422   \n",
       "\n",
       "   17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-3  \\\n",
       "0                                       0.173891   \n",
       "1                                       0.932342   \n",
       "2                                       0.119269   \n",
       "3                                       1.773602   \n",
       "4                                       0.222126   \n",
       "\n",
       "   17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-4  \\\n",
       "0                                       0.799124   \n",
       "1                                       0.394648   \n",
       "2                                       0.032103   \n",
       "3                                       0.627714   \n",
       "4                                       0.928862   \n",
       "\n",
       "   17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-5  \\\n",
       "0                                       0.573520   \n",
       "1                                       0.772451   \n",
       "2                                       0.807268   \n",
       "3                                       2.042268   \n",
       "4                                       1.004769   \n",
       "\n",
       "   17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-6  1-hexadecanol  ...  \\\n",
       "0                                       1.105910       0.677833  ...   \n",
       "1                                       0.623514       0.769287  ...   \n",
       "2                                       0.339667       1.104029  ...   \n",
       "3                                       0.913226       0.741269  ...   \n",
       "4                                       0.403102       0.790744  ...   \n",
       "\n",
       "   tyrosine-1  tyrosine-2    urea-1    urea-2    urea-3    urea-4   uridine  \\\n",
       "0    0.689488    0.037373  0.595031  0.234936  0.589201  0.127788  0.113960   \n",
       "1    0.537845    0.016517  0.484474  0.564398  0.482784  0.119055  0.009865   \n",
       "2    0.679699    1.079720  0.901623  0.559234  0.866856  0.159342  0.026922   \n",
       "3    0.837193    0.522064  1.433745  1.442062  1.406062  0.231101  0.278952   \n",
       "4    0.826921    0.462153  1.040359  1.154850  1.034635  0.198105  0.868354   \n",
       "\n",
       "     valine  xanthine  xanthosine  \n",
       "0  0.216687  0.770860    0.174060  \n",
       "1  0.164879  0.456740    0.320723  \n",
       "2  0.252849  0.473077    0.158255  \n",
       "3  0.301997  0.940990    1.095022  \n",
       "4  0.302138  1.208439    0.557425  \n",
       "\n",
       "[5 rows x 546 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../data/ST001937.csv')\n",
    "\n",
    "# Rimuoviamo le colonne che non ci servono\n",
    "df.drop(columns=[\"Sample ID\", \"RAW_FILE_NAME\"], inplace=True)\n",
    "\n",
    "# Visualizziamo le prime 5 righe del dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che il dataset non presenta alcun nullo, di conseguenza non dobbiamo effettuare nessuna operazione di imputazione. Dobbiamo soltanto modificare i valori testuali della feature Pheotypes in valori numerici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pheotypes                                        0\n",
      "1,3,5(10)-estratrien-3,6- beta-17-beta-triol     0\n",
      "1,5-anhydroglucitol                              0\n",
      "17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-1    0\n",
      "17-alpha-20-alpha-dihydroxy-4-pregnen-3-one-2    0\n",
      "                                                ..\n",
      "urea-4                                           0\n",
      "uridine                                          0\n",
      "valine                                           0\n",
      "xanthine                                         0\n",
      "xanthosine                                       0\n",
      "Length: 546, dtype: int64\n",
      "----------------------------------------------------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Visualizziamo le colonne con dati mancanti\n",
    "print(df.isnull().sum())\n",
    "print(\"----------------------------------------------------\")\n",
    "print(df.isnull().sum().sum())\n",
    "\n",
    "df['Pheotypes'] = df['Pheotypes'].apply(lambda x: 0 if x == 'Healthy Controls' else 1 if x == 'Benign SPNS' else 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Pheotypes'])\n",
    "X_features_names = X.columns\n",
    "y = df.Pheotypes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initial Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo il modello AdaBoost con gli iperparametri di default\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# Addestriamo il modello\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Eseguiamo le previsioni sui dati di test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Initial Model Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.8448275862068966\n",
      "Precision: 0.7206349206349206\n",
      "Recall: 0.6723463647368796\n",
      "F1: 0.6730541296273111\n",
      "--------------------------------\n",
      "Matrice di confusione \n",
      "[[ 48   0   2]\n",
      " [  0   3  28]\n",
      " [  0   6 145]]\n"
     ]
    }
   ],
   "source": [
    "# Visualizziamo le metriche\n",
    "print(f'Accuratezza: {metrics.accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {metrics.precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'Recall: {metrics.recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1: {metrics.f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(\"--------------------------------\")\n",
    "print(f'Matrice di confusione \\n{metrics.confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prestazioni iniziali sono ottime: abbiamo un'accuratezza di 84%. Proviamo con la K-Fold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=5, Accuratezza Media: 0.810344827586207\n",
      "K=6, Accuratezza Media: 0.8103288641988499\n",
      "K=7, Accuratezza Media: 0.815573984248683\n",
      "K=8, Accuratezza Media: 0.7956896551724137\n",
      "K=9, Accuratezza Media: 0.809505544788975\n",
      "K=10, Accuratezza Media: 0.7879310344827586\n",
      "-------------------------------------------\n",
      "K ottimale: 7\n",
      "Accuratezza media ottimale: 0.815573984248683\n"
     ]
    }
   ],
   "source": [
    "# Testiamo diverse configurazioni di K\n",
    "max = 0\n",
    "k_best = 0\n",
    "model = AdaBoostClassifier()\n",
    "for k in range(5, 11): \n",
    "    kfolds = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=kfolds)\n",
    "    mean = np.mean(scores)\n",
    "    if mean > max: \n",
    "        max = mean\n",
    "        k_best = k\n",
    "    print(f\"K={k}, Accuratezza Media: {mean}\")\n",
    "    \n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"K ottimale: {k_best}\")\n",
    "print(f\"Accuratezza media ottimale: {max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo ottenuto le prestazioni migliori con un numero di fold pari a 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo l'oggetto K-Fold per la Cross-Validation con il numero di fold ottimale\n",
    "kfolds = KFold(n_splits=k_best, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'**ottimizzazione degli iperparametri** è un passo fondamentale nello sviluppo di modelli predittivi robusti. Infatti, aderire ai parametri predefiniti impedisce ai modelli di raggiungere il massimo delle prestazioni. A tale scopo, utilizziamo la tecnica **Grid Search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Creiamo l'oggetto GridSearchCV\u001b[39;00m\n\u001b[1;32m     14\u001b[0m grid_search_model \u001b[38;5;241m=\u001b[39m GridSearchCV(model_2, param_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mkfolds, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mgrid_search_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Visualizziamo i risultati\u001b[39;00m\n\u001b[1;32m     18\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search_model\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/joblib/parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/joblib/parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1587\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1698\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1699\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creiamo un nuovo modello AdaBoost\n",
    "model_2 = AdaBoostClassifier()\n",
    "\n",
    "# Definiamo la griglia con i parametri da testare\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],           \n",
    "    'learning_rate': [0.01, 0.1, 1.0, 10],        \n",
    "    'estimator': [None, DecisionTreeClassifier(max_depth=1)],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],    \n",
    "    'random_state': [42]                      \n",
    "}\n",
    "\n",
    "# Creiamo l'oggetto GridSearchCV\n",
    "grid_search_model = GridSearchCV(model_2, param_grid, scoring='accuracy', cv=kfolds, n_jobs=-1)\n",
    "grid_search_model.fit(X, y)\n",
    "\n",
    "# Visualizziamo i risultati\n",
    "best_params = grid_search_model.best_params_\n",
    "print(\"Iperparametri migliori:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizziamo gli iperparametri ottimizzati per creare un nuovo modello\n",
    "best_model = AdaBoostClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.8577586206896551\n",
      "Precision: 0.9402173913043478\n",
      "Recall: 0.6533333333333333\n",
      "F1: 0.6270281246827089\n",
      "--------------------------------\n",
      "Matrice di confusione \n",
      "[[ 48   0   2]\n",
      " [  0   0  31]\n",
      " [  0   0 151]]\n"
     ]
    }
   ],
   "source": [
    "# Visualizziamo le metriche\n",
    "print(f'Accuratezza: {metrics.accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {metrics.precision_score(y_test, y_pred, average=\"macro\", zero_division=1)}')\n",
    "print(f'Recall: {metrics.recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(f'F1: {metrics.f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "print(\"--------------------------------\")\n",
    "print(f'Matrice di confusione \\n{metrics.confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutiamo le prestazioni con la K-Fold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza media: 0.8577895999582746\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross Validation\n",
    "scores = cross_val_score(best_model, X, y, cv=kfolds, scoring='accuracy')\n",
    "print(f'Accuratezza media: {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la feature selection, al contrario di altri dataset già esaminati, non possiamo utilizzare il test del chi-quadro in quanto esso supporta solo dati non negativi. Per questo motivo, proviamo a utilizzare la tecnica *F-Classif* calcola il valore *F-statistic* e il *p-value* associato per ogni feature rispetto alla variabile target. L'*F-statistic* misura la differenza tra le medie dei gruppi rispetto alla varianza dei dati all'interno dei gruppi. Il *p-value* è quindi utilizzato per valutare la significatività statistica della differenza osservata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2, Accuratezza Media: 0.7223960778177645\n",
      "K=3, Accuratezza Media: 0.761211078078548\n",
      "K=4, Accuratezza Media: 0.8060710373963386\n",
      "K=5, Accuratezza Media: 0.8207062014290931\n",
      "K=6, Accuratezza Media: 0.8224378031606948\n",
      "K=7, Accuratezza Media: 0.818140092838888\n",
      "K=8, Accuratezza Media: 0.8198612632347572\n",
      "K=9, Accuratezza Media: 0.8198612632347572\n",
      "K=10, Accuratezza Media: 0.818140092838888\n",
      "K=11, Accuratezza Media: 0.8345329369425755\n",
      "K=12, Accuratezza Media: 0.8422834193918531\n",
      "K=13, Accuratezza Media: 0.8414280498617848\n",
      "K=14, Accuratezza Media: 0.8414228341939186\n",
      "K=15, Accuratezza Media: 0.8396808011265843\n",
      "K=16, Accuratezza Media: 0.8465863453815262\n",
      "K=17, Accuratezza Media: 0.8457205445157253\n",
      "K=18, Accuratezza Media: 0.8465759140457936\n",
      "K=19, Accuratezza Media: 0.8534762426328691\n",
      "K=20, Accuratezza Media: 0.8543420434986702\n",
      "K=21, Accuratezza Media: 0.8560788608981379\n",
      "K=22, Accuratezza Media: 0.8543524748344026\n",
      "K=23, Accuratezza Media: 0.8543524748344026\n",
      "K=24, Accuratezza Media: 0.8543524748344026\n",
      "K=25, Accuratezza Media: 0.8543524748344026\n",
      "K=26, Accuratezza Media: 0.852626088770667\n",
      "K=27, Accuratezza Media: 0.8534762426328691\n",
      "K=28, Accuratezza Media: 0.8534762426328691\n",
      "K=29, Accuratezza Media: 0.8526156574349345\n",
      "K=30, Accuratezza Media: 0.8526156574349345\n",
      "K=31, Accuratezza Media: 0.8534814583007354\n",
      "K=32, Accuratezza Media: 0.8543420434986702\n",
      "K=33, Accuratezza Media: 0.8543420434986702\n",
      "K=34, Accuratezza Media: 0.855207844364471\n",
      "K=35, Accuratezza Media: 0.8560684295624055\n",
      "K=36, Accuratezza Media: 0.8560684295624055\n",
      "K=37, Accuratezza Media: 0.8560684295624055\n",
      "K=38, Accuratezza Media: 0.8560684295624055\n",
      "K=39, Accuratezza Media: 0.855207844364471\n",
      "K=40, Accuratezza Media: 0.855207844364471\n",
      "K=41, Accuratezza Media: 0.855207844364471\n",
      "K=42, Accuratezza Media: 0.8534814583007354\n",
      "K=43, Accuratezza Media: 0.8534814583007354\n",
      "K=44, Accuratezza Media: 0.8534814583007354\n",
      "K=45, Accuratezza Media: 0.8534762426328693\n",
      "K=46, Accuratezza Media: 0.8534762426328693\n",
      "K=47, Accuratezza Media: 0.8526156574349345\n",
      "K=48, Accuratezza Media: 0.8526156574349345\n",
      "K=49, Accuratezza Media: 0.8526156574349345\n",
      "K=50, Accuratezza Media: 0.8526156574349345\n",
      "K=51, Accuratezza Media: 0.8526156574349345\n",
      "K=52, Accuratezza Media: 0.8526156574349345\n",
      "K=53, Accuratezza Media: 0.8526156574349345\n",
      "K=54, Accuratezza Media: 0.8526156574349345\n",
      "K=55, Accuratezza Media: 0.8526156574349345\n",
      "K=56, Accuratezza Media: 0.8526156574349345\n",
      "K=57, Accuratezza Media: 0.8526156574349345\n",
      "K=58, Accuratezza Media: 0.8526156574349345\n",
      "K=59, Accuratezza Media: 0.8534814583007354\n",
      "K=60, Accuratezza Media: 0.8534814583007354\n",
      "K=61, Accuratezza Media: 0.8534814583007354\n",
      "K=62, Accuratezza Media: 0.8543420434986702\n",
      "K=63, Accuratezza Media: 0.8543420434986702\n",
      "K=64, Accuratezza Media: 0.8543420434986702\n",
      "K=65, Accuratezza Media: 0.8543420434986702\n",
      "K=66, Accuratezza Media: 0.8543420434986702\n",
      "K=67, Accuratezza Media: 0.8543420434986702\n",
      "K=68, Accuratezza Media: 0.8543420434986702\n",
      "K=69, Accuratezza Media: 0.8543420434986702\n",
      "K=70, Accuratezza Media: 0.8543420434986702\n",
      "K=71, Accuratezza Media: 0.8543420434986702\n",
      "K=72, Accuratezza Media: 0.8543420434986702\n",
      "K=73, Accuratezza Media: 0.8534814583007354\n",
      "K=74, Accuratezza Media: 0.8534814583007354\n",
      "K=75, Accuratezza Media: 0.8534762426328691\n",
      "K=76, Accuratezza Media: 0.8534762426328691\n",
      "K=77, Accuratezza Media: 0.8534762426328691\n",
      "K=78, Accuratezza Media: 0.8534762426328691\n",
      "K=79, Accuratezza Media: 0.8534762426328691\n",
      "K=80, Accuratezza Media: 0.8534762426328691\n",
      "K=81, Accuratezza Media: 0.8534762426328691\n",
      "K=82, Accuratezza Media: 0.8534762426328691\n",
      "K=83, Accuratezza Media: 0.8526104417670683\n",
      "K=84, Accuratezza Media: 0.8526104417670683\n",
      "K=85, Accuratezza Media: 0.8526104417670683\n",
      "K=86, Accuratezza Media: 0.8526104417670683\n",
      "K=87, Accuratezza Media: 0.8526104417670683\n",
      "K=88, Accuratezza Media: 0.8526104417670683\n",
      "K=89, Accuratezza Media: 0.8534710269650028\n",
      "K=90, Accuratezza Media: 0.8534710269650028\n",
      "K=91, Accuratezza Media: 0.8543368278308037\n",
      "K=92, Accuratezza Media: 0.8543368278308037\n",
      "K=93, Accuratezza Media: 0.8543368278308037\n",
      "K=94, Accuratezza Media: 0.8543368278308037\n",
      "K=95, Accuratezza Media: 0.8534710269650028\n",
      "K=96, Accuratezza Media: 0.8534710269650028\n",
      "K=97, Accuratezza Media: 0.8534710269650028\n",
      "K=98, Accuratezza Media: 0.8534710269650028\n",
      "K=99, Accuratezza Media: 0.8534710269650028\n",
      "K=100, Accuratezza Media: 0.8534710269650028\n",
      "K=101, Accuratezza Media: 0.8534710269650028\n",
      "K=102, Accuratezza Media: 0.8526104417670683\n",
      "K=103, Accuratezza Media: 0.8526104417670683\n",
      "K=104, Accuratezza Media: 0.8526104417670683\n",
      "K=105, Accuratezza Media: 0.8526104417670683\n",
      "K=106, Accuratezza Media: 0.8526104417670683\n",
      "K=107, Accuratezza Media: 0.8517446409012673\n",
      "K=108, Accuratezza Media: 0.8517446409012673\n",
      "K=109, Accuratezza Media: 0.8517446409012673\n",
      "K=110, Accuratezza Media: 0.8517446409012673\n",
      "K=111, Accuratezza Media: 0.8560632138945393\n",
      "K=112, Accuratezza Media: 0.8560632138945393\n",
      "K=113, Accuratezza Media: 0.8560632138945393\n",
      "K=114, Accuratezza Media: 0.8560632138945393\n",
      "K=115, Accuratezza Media: 0.8560632138945393\n",
      "K=116, Accuratezza Media: 0.8543316121629375\n",
      "K=117, Accuratezza Media: 0.8543316121629375\n",
      "K=118, Accuratezza Media: 0.8543316121629375\n",
      "K=119, Accuratezza Media: 0.8508788400354665\n",
      "K=120, Accuratezza Media: 0.8508788400354665\n",
      "K=121, Accuratezza Media: 0.8508788400354665\n",
      "K=122, Accuratezza Media: 0.8543368278308038\n",
      "K=123, Accuratezza Media: 0.8543368278308038\n",
      "K=124, Accuratezza Media: 0.8543368278308038\n",
      "K=125, Accuratezza Media: 0.8543368278308038\n",
      "K=126, Accuratezza Media: 0.8543368278308038\n",
      "K=127, Accuratezza Media: 0.8543368278308038\n",
      "K=128, Accuratezza Media: 0.8543368278308038\n",
      "K=129, Accuratezza Media: 0.8543368278308038\n",
      "K=130, Accuratezza Media: 0.8543368278308038\n",
      "K=131, Accuratezza Media: 0.8543368278308038\n",
      "K=132, Accuratezza Media: 0.8543368278308038\n",
      "K=133, Accuratezza Media: 0.8543368278308038\n",
      "K=134, Accuratezza Media: 0.8543368278308038\n",
      "K=135, Accuratezza Media: 0.8543368278308038\n",
      "K=136, Accuratezza Media: 0.8543368278308038\n",
      "K=137, Accuratezza Media: 0.8534710269650029\n",
      "K=138, Accuratezza Media: 0.8534710269650029\n",
      "K=139, Accuratezza Media: 0.8534710269650029\n",
      "K=140, Accuratezza Media: 0.8534710269650029\n",
      "K=141, Accuratezza Media: 0.8534710269650029\n",
      "K=142, Accuratezza Media: 0.8534710269650029\n",
      "K=143, Accuratezza Media: 0.8534710269650029\n",
      "K=144, Accuratezza Media: 0.8526104417670682\n",
      "K=145, Accuratezza Media: 0.8517498565691337\n",
      "K=146, Accuratezza Media: 0.8517498565691337\n",
      "K=147, Accuratezza Media: 0.8517498565691337\n",
      "K=148, Accuratezza Media: 0.8517498565691337\n",
      "K=149, Accuratezza Media: 0.8517498565691337\n",
      "K=150, Accuratezza Media: 0.8517498565691337\n",
      "K=151, Accuratezza Media: 0.8517498565691337\n",
      "K=152, Accuratezza Media: 0.8517498565691337\n",
      "K=153, Accuratezza Media: 0.8517498565691337\n",
      "K=154, Accuratezza Media: 0.850889271371199\n",
      "K=155, Accuratezza Media: 0.850889271371199\n",
      "K=156, Accuratezza Media: 0.850889271371199\n",
      "K=157, Accuratezza Media: 0.850889271371199\n",
      "K=158, Accuratezza Media: 0.850889271371199\n",
      "K=159, Accuratezza Media: 0.850889271371199\n",
      "K=160, Accuratezza Media: 0.850889271371199\n",
      "K=161, Accuratezza Media: 0.850889271371199\n",
      "K=162, Accuratezza Media: 0.850889271371199\n",
      "K=163, Accuratezza Media: 0.850889271371199\n",
      "K=164, Accuratezza Media: 0.8517498565691335\n",
      "K=165, Accuratezza Media: 0.8517498565691335\n",
      "K=166, Accuratezza Media: 0.8517498565691335\n",
      "K=167, Accuratezza Media: 0.8517498565691335\n",
      "K=168, Accuratezza Media: 0.8517498565691335\n",
      "K=169, Accuratezza Media: 0.8517498565691335\n",
      "K=170, Accuratezza Media: 0.8517498565691335\n",
      "K=171, Accuratezza Media: 0.8517498565691335\n",
      "K=172, Accuratezza Media: 0.8517498565691335\n",
      "K=173, Accuratezza Media: 0.8517498565691335\n",
      "K=174, Accuratezza Media: 0.8534710269650027\n",
      "K=175, Accuratezza Media: 0.8534710269650027\n",
      "K=176, Accuratezza Media: 0.8534762426328693\n",
      "K=177, Accuratezza Media: 0.8534762426328693\n",
      "K=178, Accuratezza Media: 0.8534762426328693\n",
      "K=179, Accuratezza Media: 0.8534762426328693\n",
      "K=180, Accuratezza Media: 0.8534762426328693\n",
      "K=181, Accuratezza Media: 0.8534762426328693\n",
      "K=182, Accuratezza Media: 0.8534762426328693\n",
      "K=183, Accuratezza Media: 0.8534762426328693\n",
      "K=184, Accuratezza Media: 0.8534762426328693\n",
      "K=185, Accuratezza Media: 0.8500234705053982\n",
      "K=186, Accuratezza Media: 0.8500234705053982\n",
      "K=187, Accuratezza Media: 0.8500234705053982\n",
      "K=188, Accuratezza Media: 0.8500234705053982\n",
      "K=189, Accuratezza Media: 0.8500234705053982\n",
      "K=190, Accuratezza Media: 0.8500234705053982\n",
      "K=191, Accuratezza Media: 0.8500234705053982\n",
      "K=192, Accuratezza Media: 0.8500234705053982\n",
      "K=193, Accuratezza Media: 0.8500234705053982\n",
      "K=194, Accuratezza Media: 0.8500234705053982\n",
      "K=195, Accuratezza Media: 0.8500234705053982\n",
      "K=196, Accuratezza Media: 0.8500234705053982\n",
      "K=197, Accuratezza Media: 0.8500234705053982\n",
      "K=198, Accuratezza Media: 0.8500234705053982\n",
      "K=199, Accuratezza Media: 0.8500234705053982\n",
      "K=200, Accuratezza Media: 0.8500234705053982\n",
      "K=201, Accuratezza Media: 0.8500234705053982\n",
      "K=202, Accuratezza Media: 0.8500234705053982\n",
      "K=203, Accuratezza Media: 0.8500234705053982\n",
      "K=204, Accuratezza Media: 0.8500234705053982\n",
      "K=205, Accuratezza Media: 0.8500234705053982\n",
      "K=206, Accuratezza Media: 0.8500234705053982\n",
      "K=207, Accuratezza Media: 0.8500234705053982\n",
      "K=208, Accuratezza Media: 0.8500234705053982\n",
      "K=209, Accuratezza Media: 0.8500234705053982\n",
      "K=210, Accuratezza Media: 0.8500234705053982\n",
      "K=211, Accuratezza Media: 0.8500234705053982\n",
      "K=212, Accuratezza Media: 0.8500234705053982\n",
      "K=213, Accuratezza Media: 0.8500234705053982\n",
      "K=214, Accuratezza Media: 0.8500234705053982\n",
      "K=215, Accuratezza Media: 0.8500234705053982\n",
      "K=216, Accuratezza Media: 0.8500234705053982\n",
      "K=217, Accuratezza Media: 0.8500234705053982\n",
      "K=218, Accuratezza Media: 0.8500234705053982\n",
      "K=219, Accuratezza Media: 0.8500234705053982\n",
      "K=220, Accuratezza Media: 0.8500234705053982\n",
      "K=221, Accuratezza Media: 0.8500234705053982\n",
      "K=222, Accuratezza Media: 0.8500234705053982\n",
      "K=223, Accuratezza Media: 0.8500234705053982\n",
      "K=224, Accuratezza Media: 0.8500234705053982\n",
      "K=225, Accuratezza Media: 0.8508840557033329\n",
      "K=226, Accuratezza Media: 0.8508840557033329\n",
      "K=227, Accuratezza Media: 0.8508840557033329\n",
      "K=228, Accuratezza Media: 0.8508840557033329\n",
      "K=229, Accuratezza Media: 0.8526156574349345\n",
      "K=230, Accuratezza Media: 0.8526156574349345\n",
      "K=231, Accuratezza Media: 0.8526156574349345\n",
      "K=232, Accuratezza Media: 0.8526156574349345\n",
      "K=233, Accuratezza Media: 0.8526156574349345\n",
      "K=234, Accuratezza Media: 0.8526156574349345\n",
      "K=235, Accuratezza Media: 0.8526156574349345\n",
      "K=236, Accuratezza Media: 0.8526156574349345\n",
      "K=237, Accuratezza Media: 0.8534814583007354\n",
      "K=238, Accuratezza Media: 0.8534814583007354\n",
      "K=239, Accuratezza Media: 0.8534814583007354\n",
      "K=240, Accuratezza Media: 0.8534814583007354\n",
      "K=241, Accuratezza Media: 0.8534814583007354\n",
      "K=242, Accuratezza Media: 0.8534814583007354\n",
      "K=243, Accuratezza Media: 0.8534814583007354\n",
      "K=244, Accuratezza Media: 0.8534814583007354\n",
      "K=245, Accuratezza Media: 0.8534814583007354\n",
      "K=246, Accuratezza Media: 0.8534814583007354\n",
      "K=247, Accuratezza Media: 0.8534814583007354\n",
      "K=248, Accuratezza Media: 0.8534814583007354\n",
      "K=249, Accuratezza Media: 0.8534814583007354\n",
      "K=250, Accuratezza Media: 0.8534814583007354\n",
      "K=251, Accuratezza Media: 0.8534814583007354\n",
      "K=252, Accuratezza Media: 0.8534814583007354\n",
      "K=253, Accuratezza Media: 0.8534814583007354\n",
      "K=254, Accuratezza Media: 0.8534814583007354\n",
      "K=255, Accuratezza Media: 0.8534814583007354\n",
      "K=256, Accuratezza Media: 0.8534814583007354\n",
      "K=257, Accuratezza Media: 0.8534814583007354\n",
      "K=258, Accuratezza Media: 0.8534814583007354\n",
      "K=259, Accuratezza Media: 0.8534814583007354\n",
      "K=260, Accuratezza Media: 0.8534814583007354\n",
      "K=261, Accuratezza Media: 0.8534814583007354\n",
      "K=262, Accuratezza Media: 0.8534814583007354\n",
      "K=263, Accuratezza Media: 0.8534814583007354\n",
      "K=264, Accuratezza Media: 0.8534814583007354\n",
      "K=265, Accuratezza Media: 0.8534814583007354\n",
      "K=266, Accuratezza Media: 0.8534814583007354\n",
      "K=267, Accuratezza Media: 0.8534814583007354\n",
      "K=268, Accuratezza Media: 0.8534814583007354\n",
      "K=269, Accuratezza Media: 0.8534814583007354\n",
      "K=270, Accuratezza Media: 0.8534814583007354\n",
      "K=271, Accuratezza Media: 0.8534814583007354\n",
      "K=272, Accuratezza Media: 0.8534814583007354\n",
      "K=273, Accuratezza Media: 0.8534814583007354\n",
      "K=274, Accuratezza Media: 0.8534814583007354\n",
      "K=275, Accuratezza Media: 0.8534814583007354\n",
      "K=276, Accuratezza Media: 0.8534814583007354\n",
      "K=277, Accuratezza Media: 0.8534814583007354\n",
      "K=278, Accuratezza Media: 0.8534814583007354\n",
      "K=279, Accuratezza Media: 0.8534814583007354\n",
      "K=280, Accuratezza Media: 0.8534814583007354\n",
      "K=281, Accuratezza Media: 0.8534814583007354\n",
      "K=282, Accuratezza Media: 0.8534814583007354\n",
      "K=283, Accuratezza Media: 0.8534814583007354\n",
      "K=284, Accuratezza Media: 0.8534814583007354\n",
      "K=285, Accuratezza Media: 0.8534814583007354\n",
      "K=286, Accuratezza Media: 0.8534814583007354\n",
      "K=287, Accuratezza Media: 0.8534814583007354\n",
      "K=288, Accuratezza Media: 0.8534814583007354\n",
      "K=289, Accuratezza Media: 0.8534814583007354\n",
      "K=290, Accuratezza Media: 0.8534814583007354\n",
      "K=291, Accuratezza Media: 0.8534814583007354\n",
      "K=292, Accuratezza Media: 0.8534814583007354\n",
      "K=293, Accuratezza Media: 0.8534814583007354\n",
      "K=294, Accuratezza Media: 0.8534814583007354\n",
      "K=295, Accuratezza Media: 0.8534814583007354\n",
      "K=296, Accuratezza Media: 0.8534814583007354\n",
      "K=297, Accuratezza Media: 0.8534814583007354\n",
      "K=298, Accuratezza Media: 0.8534814583007354\n",
      "K=299, Accuratezza Media: 0.8534814583007354\n",
      "K=300, Accuratezza Media: 0.8534814583007354\n",
      "K=301, Accuratezza Media: 0.8534814583007354\n",
      "K=302, Accuratezza Media: 0.8534814583007354\n",
      "K=303, Accuratezza Media: 0.8534814583007354\n",
      "K=304, Accuratezza Media: 0.8534814583007354\n",
      "K=305, Accuratezza Media: 0.8534814583007354\n",
      "K=306, Accuratezza Media: 0.8534814583007354\n",
      "K=307, Accuratezza Media: 0.8534814583007354\n",
      "K=308, Accuratezza Media: 0.8534814583007354\n",
      "K=309, Accuratezza Media: 0.8534814583007354\n",
      "K=310, Accuratezza Media: 0.8534814583007354\n",
      "K=311, Accuratezza Media: 0.8534814583007354\n",
      "K=312, Accuratezza Media: 0.8534814583007354\n",
      "K=313, Accuratezza Media: 0.8534814583007354\n",
      "K=314, Accuratezza Media: 0.8534814583007354\n",
      "K=315, Accuratezza Media: 0.8534814583007354\n",
      "K=316, Accuratezza Media: 0.8534814583007354\n",
      "K=317, Accuratezza Media: 0.8534814583007354\n",
      "K=318, Accuratezza Media: 0.8534814583007354\n",
      "K=319, Accuratezza Media: 0.8534814583007354\n",
      "K=320, Accuratezza Media: 0.8534814583007354\n",
      "K=321, Accuratezza Media: 0.8534814583007354\n",
      "K=322, Accuratezza Media: 0.8534814583007354\n",
      "K=323, Accuratezza Media: 0.8534814583007354\n",
      "K=324, Accuratezza Media: 0.8534814583007354\n",
      "K=325, Accuratezza Media: 0.8534814583007354\n",
      "K=326, Accuratezza Media: 0.8534814583007354\n",
      "K=327, Accuratezza Media: 0.8534814583007354\n",
      "K=328, Accuratezza Media: 0.8534814583007354\n",
      "K=329, Accuratezza Media: 0.8534814583007354\n",
      "K=330, Accuratezza Media: 0.8534814583007354\n",
      "K=331, Accuratezza Media: 0.8534814583007354\n",
      "K=332, Accuratezza Media: 0.8534814583007354\n",
      "K=333, Accuratezza Media: 0.8534814583007354\n",
      "K=334, Accuratezza Media: 0.8534814583007354\n",
      "K=335, Accuratezza Media: 0.8534814583007354\n",
      "K=336, Accuratezza Media: 0.8534814583007354\n",
      "K=337, Accuratezza Media: 0.8534814583007354\n",
      "K=338, Accuratezza Media: 0.8552026286966046\n",
      "K=339, Accuratezza Media: 0.8552026286966046\n",
      "K=340, Accuratezza Media: 0.8552026286966046\n",
      "K=341, Accuratezza Media: 0.8552026286966046\n",
      "K=342, Accuratezza Media: 0.8552026286966046\n",
      "K=343, Accuratezza Media: 0.8552026286966046\n",
      "K=344, Accuratezza Media: 0.8552026286966046\n",
      "K=345, Accuratezza Media: 0.8552026286966046\n",
      "K=346, Accuratezza Media: 0.8552026286966046\n",
      "K=347, Accuratezza Media: 0.8552026286966046\n",
      "K=348, Accuratezza Media: 0.8569290147603402\n",
      "K=349, Accuratezza Media: 0.8569290147603402\n",
      "K=350, Accuratezza Media: 0.8569290147603402\n",
      "K=351, Accuratezza Media: 0.8569290147603402\n",
      "K=352, Accuratezza Media: 0.8586554008240755\n",
      "K=353, Accuratezza Media: 0.8586554008240755\n",
      "K=354, Accuratezza Media: 0.8586554008240755\n",
      "K=355, Accuratezza Media: 0.8586554008240755\n",
      "K=356, Accuratezza Media: 0.8586554008240755\n",
      "K=357, Accuratezza Media: 0.8586554008240755\n",
      "K=358, Accuratezza Media: 0.8586554008240755\n",
      "K=359, Accuratezza Media: 0.8586554008240755\n",
      "K=360, Accuratezza Media: 0.8586554008240755\n",
      "K=361, Accuratezza Media: 0.8586554008240755\n",
      "K=362, Accuratezza Media: 0.8586554008240755\n",
      "K=363, Accuratezza Media: 0.8586554008240755\n",
      "K=364, Accuratezza Media: 0.8586554008240755\n",
      "K=365, Accuratezza Media: 0.8586554008240755\n",
      "K=366, Accuratezza Media: 0.8577895999582746\n",
      "K=367, Accuratezza Media: 0.8577895999582746\n",
      "K=368, Accuratezza Media: 0.8577895999582746\n",
      "K=369, Accuratezza Media: 0.8577895999582746\n",
      "K=370, Accuratezza Media: 0.8577895999582746\n",
      "K=371, Accuratezza Media: 0.8577895999582746\n",
      "K=372, Accuratezza Media: 0.8577895999582746\n",
      "K=373, Accuratezza Media: 0.8577895999582746\n",
      "K=374, Accuratezza Media: 0.8577895999582746\n",
      "K=375, Accuratezza Media: 0.8577895999582746\n",
      "K=376, Accuratezza Media: 0.8577895999582746\n",
      "K=377, Accuratezza Media: 0.8577895999582746\n",
      "K=378, Accuratezza Media: 0.8577895999582746\n",
      "K=379, Accuratezza Media: 0.8577895999582746\n",
      "K=380, Accuratezza Media: 0.8577895999582746\n",
      "K=381, Accuratezza Media: 0.857794815626141\n",
      "K=382, Accuratezza Media: 0.857794815626141\n",
      "K=383, Accuratezza Media: 0.857794815626141\n",
      "K=384, Accuratezza Media: 0.857794815626141\n",
      "K=385, Accuratezza Media: 0.857794815626141\n",
      "K=386, Accuratezza Media: 0.857794815626141\n",
      "K=387, Accuratezza Media: 0.857794815626141\n",
      "K=388, Accuratezza Media: 0.857794815626141\n",
      "K=389, Accuratezza Media: 0.857794815626141\n",
      "K=390, Accuratezza Media: 0.857794815626141\n",
      "K=391, Accuratezza Media: 0.857794815626141\n",
      "K=392, Accuratezza Media: 0.857794815626141\n",
      "K=393, Accuratezza Media: 0.857794815626141\n",
      "K=394, Accuratezza Media: 0.857794815626141\n",
      "K=395, Accuratezza Media: 0.857794815626141\n",
      "K=396, Accuratezza Media: 0.857794815626141\n",
      "K=397, Accuratezza Media: 0.857794815626141\n",
      "K=398, Accuratezza Media: 0.857794815626141\n",
      "K=399, Accuratezza Media: 0.8569290147603402\n",
      "K=400, Accuratezza Media: 0.8569290147603402\n",
      "K=401, Accuratezza Media: 0.8569290147603402\n",
      "K=402, Accuratezza Media: 0.8569290147603402\n",
      "K=403, Accuratezza Media: 0.8569290147603402\n",
      "K=404, Accuratezza Media: 0.8569290147603402\n",
      "K=405, Accuratezza Media: 0.8569290147603402\n",
      "K=406, Accuratezza Media: 0.8569290147603402\n",
      "K=407, Accuratezza Media: 0.8569290147603402\n",
      "K=408, Accuratezza Media: 0.8569290147603402\n",
      "K=409, Accuratezza Media: 0.8569290147603402\n",
      "K=410, Accuratezza Media: 0.8569290147603402\n",
      "K=411, Accuratezza Media: 0.8569290147603402\n",
      "K=412, Accuratezza Media: 0.8569290147603402\n",
      "K=413, Accuratezza Media: 0.8569290147603402\n",
      "K=414, Accuratezza Media: 0.8569290147603402\n",
      "K=415, Accuratezza Media: 0.8569290147603402\n",
      "K=416, Accuratezza Media: 0.8569290147603402\n",
      "K=417, Accuratezza Media: 0.8569290147603402\n",
      "K=418, Accuratezza Media: 0.8569290147603402\n",
      "K=419, Accuratezza Media: 0.8569290147603402\n",
      "K=420, Accuratezza Media: 0.8569290147603402\n",
      "K=421, Accuratezza Media: 0.8569290147603402\n",
      "K=422, Accuratezza Media: 0.8569290147603402\n",
      "K=423, Accuratezza Media: 0.8569290147603402\n",
      "K=424, Accuratezza Media: 0.8569290147603402\n",
      "K=425, Accuratezza Media: 0.8569290147603402\n",
      "K=426, Accuratezza Media: 0.8569290147603402\n",
      "K=427, Accuratezza Media: 0.8569290147603402\n",
      "K=428, Accuratezza Media: 0.8569290147603402\n",
      "K=429, Accuratezza Media: 0.8569290147603402\n",
      "K=430, Accuratezza Media: 0.8577895999582746\n",
      "K=431, Accuratezza Media: 0.8577895999582746\n",
      "K=432, Accuratezza Media: 0.8577895999582746\n",
      "K=433, Accuratezza Media: 0.8577895999582746\n",
      "K=434, Accuratezza Media: 0.8577895999582746\n",
      "K=435, Accuratezza Media: 0.8577895999582746\n",
      "K=436, Accuratezza Media: 0.8577895999582746\n",
      "K=437, Accuratezza Media: 0.8577895999582746\n",
      "K=438, Accuratezza Media: 0.856057998226673\n",
      "K=439, Accuratezza Media: 0.8569237990924737\n",
      "K=440, Accuratezza Media: 0.8569237990924737\n",
      "K=441, Accuratezza Media: 0.8569237990924737\n",
      "K=442, Accuratezza Media: 0.8569237990924737\n",
      "K=443, Accuratezza Media: 0.8569237990924737\n",
      "K=444, Accuratezza Media: 0.8569237990924737\n",
      "K=445, Accuratezza Media: 0.8569237990924737\n",
      "K=446, Accuratezza Media: 0.8569237990924737\n",
      "K=447, Accuratezza Media: 0.8569237990924737\n",
      "K=448, Accuratezza Media: 0.8569237990924737\n",
      "K=449, Accuratezza Media: 0.8569237990924737\n",
      "K=450, Accuratezza Media: 0.8569237990924737\n",
      "K=451, Accuratezza Media: 0.8569237990924737\n",
      "K=452, Accuratezza Media: 0.8577895999582746\n",
      "K=453, Accuratezza Media: 0.8577895999582746\n",
      "K=454, Accuratezza Media: 0.8577895999582746\n",
      "K=455, Accuratezza Media: 0.8577895999582746\n",
      "K=456, Accuratezza Media: 0.8577895999582746\n",
      "K=457, Accuratezza Media: 0.8577895999582746\n",
      "K=458, Accuratezza Media: 0.8577895999582746\n",
      "K=459, Accuratezza Media: 0.8577895999582746\n",
      "K=460, Accuratezza Media: 0.8577895999582746\n",
      "K=461, Accuratezza Media: 0.8577895999582746\n",
      "K=462, Accuratezza Media: 0.8577895999582746\n",
      "K=463, Accuratezza Media: 0.8577895999582746\n",
      "K=464, Accuratezza Media: 0.8577895999582746\n",
      "K=465, Accuratezza Media: 0.8577895999582746\n",
      "K=466, Accuratezza Media: 0.8577895999582746\n",
      "K=467, Accuratezza Media: 0.8595212016898763\n",
      "K=468, Accuratezza Media: 0.8595212016898763\n",
      "K=469, Accuratezza Media: 0.8595212016898763\n",
      "K=470, Accuratezza Media: 0.8595212016898763\n",
      "K=471, Accuratezza Media: 0.8595212016898763\n",
      "K=472, Accuratezza Media: 0.8595212016898763\n",
      "K=473, Accuratezza Media: 0.8595212016898763\n",
      "K=474, Accuratezza Media: 0.8595212016898763\n",
      "K=475, Accuratezza Media: 0.8595212016898763\n",
      "K=476, Accuratezza Media: 0.8595212016898763\n",
      "K=477, Accuratezza Media: 0.8586554008240755\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m top_features \u001b[38;5;241m=\u001b[39m SelectKBest(score_func\u001b[38;5;241m=\u001b[39mf_classif, k\u001b[38;5;241m=\u001b[39mk)\u001b[38;5;241m.\u001b[39mfit(X, y)\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m X_top \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[:, top_features]\n\u001b[0;32m----> 9\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_top\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(scores)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean \u001b[38;5;241m>\u001b[39m max_fs: \n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:171\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    168\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:579\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:588\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    586\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m--> 588\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Programming/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_fs = 0 \n",
    "k_fs = 0\n",
    "best_features = []\n",
    "\n",
    "for k in range(2, len(X.columns)):\n",
    "    top_features = SelectKBest(score_func=f_classif, k=k).fit(X, y).get_support(indices=True)\n",
    "    X_top = X.iloc[:, top_features]\n",
    "    \n",
    "    scores = cross_val_score(best_model, X_top, y, cv=kfolds, scoring='accuracy')\n",
    "    mean = np.mean(scores)\n",
    "    \n",
    "    if mean > max_fs: \n",
    "        max_fs = mean\n",
    "        k_fs = k\n",
    "        best_features = X.columns[top_features].tolist()\n",
    "\n",
    "    print(f\"K={k}, Accuratezza Media: {mean}\")\n",
    "\n",
    "print(f\"K ottimale: {k_fs}\")\n",
    "print(f\"Accuratezza media ottimale: {max_fs}\")\n",
    "print(f\"Features ottimali: {best_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuratezza più alta si ha con le migliori 436 features, tuttavia è comunque minore dell'accuratezza su tutte e 544 le features. Di conseguenza, la feature selection non ci aiuta nelle nostre analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di features ottimali: 467\n",
      "Accuratezza media: 0.8595212016898763\n"
     ]
    }
   ],
   "source": [
    "X_top = X[best_features]\n",
    "scores = cross_val_score(best_model, X_top, y, cv=kfolds, scoring='accuracy')\n",
    "print(f'Numero di features ottimali: {X_top.shape[1]}')\n",
    "print(f'Accuratezza media: {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di componenti principali: 86\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.99) + 1\n",
    "print(\"Numero di componenti principali:\", d)\n",
    "\n",
    "pca = PCA(n_components=d)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza media: 0.7999928778733331\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(best_model, X_reduced, y, cv=kfolds, scoring='accuracy')\n",
    "print(f'Accuratezza media: {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La PCA non ci aiuta nelle nostre analisi. Infatti, è impossibile arrivare a plottare le componenti principali in quanto saranno sempre maggiori di 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo i risultati migliori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza media: 0.866371098409985\n"
     ]
    }
   ],
   "source": [
    "# Numero ottimale di fold \n",
    "kfolds = KFold(n_splits=k_best, shuffle=True, random_state=42)\n",
    "\n",
    "# Modello eXtreme Gradient Boost con gli iperparametri ottimizzati\n",
    "model = AdaBoostClassifier(**best_params)\n",
    "\n",
    "# K-Fold Cross Validation del modello con gli iperparametri ottimizzati\n",
    "scores = cross_val_score(model, X, y, cv=kfolds, scoring='accuracy')\n",
    "print(f'Accuratezza media: {scores.mean()}')\n",
    "\n",
    "# K-Fold Cross Validation del modello con gli iperparametri ottimizzati\n",
    "scores = cross_val_score(model, X_top, y, cv=kfolds, scoring='accuracy')\n",
    "print(f'Accuratezza media: {scores.mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
